
Лаборатории интеллектуальных систем ВятГУ

Для таких задач используют модели семейства Qwen, Llama и с недавних пор gemma. Размер LLM и глубину квантования можно посоветовать только исходя из понимания имеющейся видеокарты. Вариант - покупать токены у провайдеров опенсорсных LLM, но в таком случае это будет только демо вариант, т.к. выход за контур предприятия и потенциально ИБ может не пропустить. Далее. Обучение LLM на документах никто не делает - есть много исследований, которые ссылаться к тому, что это только портит модель. Грамотно обучить LLM мало кто у нас в стране может, да и железные ресурсы для этого нужны впечатляющие. Могу предложить такой вариант: отдаем вам нашу базовую RAG-систему бесплатно по соглашению, разрешающему ее неограниченное распространение и использование внутри организации, но с запретом на передачу другим юрлицам и на модификацию и использование кода или его частей. Она из коробки хорошо работает с документами, за исключением поиска по сложным таблицам, схемам и графикам. Здесь у нас скоро выйдет мультимодальный поиск, который уже умеет. 
